{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PLgEA8zf-nm6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive = pd.read_excel(\"/content/drive/MyDrive/pittsburgh-annotation-son-20240613/hate_speech_isik_llm_model_positive_preds_evaluation_offensive_hate_annotation_busra_kadir_merged_20240603_2nd.xlsx\")"
      ],
      "metadata": {
        "id": "NLDnG6Zv_QmH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWgj0EqJ_SS_",
        "outputId": "a1235438-2af3-4e3b-d8bd-eba9d567dd7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Annotator', '#', 'text', 'Dis\\nNeutral', 'Offense \\nNeutral',\n",
              "       'dis_O_ Relevant', 'Offense \\nRelevant', 'Dis_o_Physical harm',\n",
              "       'Offense Physical Harm Threat', 'dis_o_insult_prof',\n",
              "       'Offense Insult profanity', 'dis_o_insult_demean',\n",
              "       'Offense Insult\\n(Demean)', 'dis_o_ridicule',\n",
              "       'Offense Ridicule Mockery', 'dis_o_other', 'Offense \\nOther', 'dis_HS',\n",
              "       'Hate \\nSpeech', 'dis_H_eth', 'Hate \\nEthnicity', 'dis_H_rel',\n",
              "       'Hate  \\nReligion', 'Dis_H_Gen', 'Hate \\nGender', 'Dis_H_other',\n",
              "       'Hate \\nOther', 'comment'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive.rename(columns = {'Hate \\nSpeech':\"hate-speech\"},inplace=True)"
      ],
      "metadata": {
        "id": "QzKpH-15_SNV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive[\"hate-speech\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbSLr0hy_SIP",
        "outputId": "8b29e27e-ba15-49b3-efc3-d6fc9ee4786b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          1.0\n",
              "1          1.0\n",
              "2          NaN\n",
              "3          1.0\n",
              "4          1.0\n",
              "         ...  \n",
              "3226       NaN\n",
              "3227       NaN\n",
              "3228       NaN\n",
              "3229    1303.0\n",
              "3230     182.0\n",
              "Name: hate-speech, Length: 3231, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive[\"dis_HS\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpPTzs17_SF6",
        "outputId": "2dac6200-aee3-4b18-e366-126ea009920b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0              NaN\n",
              "1              NaN\n",
              "2         2.000000\n",
              "3              NaN\n",
              "4              NaN\n",
              "           ...    \n",
              "3226    412.000000\n",
              "3227    279.000000\n",
              "3228    147.670251\n",
              "3229           NaN\n",
              "3230           NaN\n",
              "Name: dis_HS, Length: 3231, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def resolve_hate_speech(group):\n",
        "    busra_value = group[group['Annotator'] == 'busra']['hate-speech'].values\n",
        "    kadir_value = group[group['Annotator'] == 'kadir']['hate-speech'].values\n",
        "    final_value = group[group['Annotator'] == 'final']['hate-speech'].values\n",
        "\n",
        "    if len(busra_value) > 0 and len(kadir_value) > 0:\n",
        "        busra_value = busra_value[0]\n",
        "        kadir_value = kadir_value[0]\n",
        "        if busra_value == kadir_value:\n",
        "            return busra_value\n",
        "        elif len(final_value) > 0:\n",
        "            return final_value[0]\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "grouped = offensive.groupby('text')\n",
        "resolved_values = grouped.apply(resolve_hate_speech)\n",
        "offensive['Resolved_Hate_Speech'] = offensive['text'].map(resolved_values).astype('Int64')\n",
        "offensive_final = offensive.drop_duplicates(subset='text', keep='first')\n",
        "offensive_final = offensive_final.reset_index(drop=True)\n",
        "offensive_final = offensive_final[['text', 'Resolved_Hate_Speech']]\n",
        "offensive_final[\"Resolved_Hate_Speech\"].astype(str)\n",
        "print(offensive_final)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zKR6La2_SDQ",
        "outputId": "08abca70-8f20-4001-c2a8-54b53da04f34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text  Resolved_Hate_Speech\n",
            "0     @meraldanis @Alone_36_ Sen o kadar vatansevers...                     1\n",
            "1     @meraldanis Erzurum'da kaza geçirmiş. Ne yazık...                     1\n",
            "2     @gulderenvarli Emekçi kürt halkın verdiği verg...                     1\n",
            "3     @meraldanis Bunlari bebek katili savunan diyor...                     1\n",
            "4     @meraldanis Dağdaki ler aç mı ?kaldı kurşunu b...                     1\n",
            "...                                                 ...                   ...\n",
            "1076                                              agree                  <NA>\n",
            "1077                                           disagree                  <NA>\n",
            "1078                                          agree/dis                  <NA>\n",
            "1079                                              total                  <NA>\n",
            "1080                                           subtotal                  <NA>\n",
            "\n",
            "[1081 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final[\"Resolved_Hate_Speech\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DGpF0k5_SAG",
        "outputId": "0d200247-6ea2-4fa5-ce69-6bb151bc82e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resolved_Hate_Speech\n",
              "1    612\n",
              "0    463\n",
              "Name: count, dtype: Int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final.rename(columns={\"Resolved_Hate_Speech\":\"labels\"},inplace=True)"
      ],
      "metadata": {
        "id": "PnHGj8Z9BzwS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nApKpu-NJAic",
        "outputId": "24cf7e91-4b49-41fd-f689-d666831e691e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  labels\n",
              "0     @meraldanis @Alone_36_ Sen o kadar vatansevers...       1\n",
              "1     @meraldanis Erzurum'da kaza geçirmiş. Ne yazık...       1\n",
              "2     @gulderenvarli Emekçi kürt halkın verdiği verg...       1\n",
              "3     @meraldanis Bunlari bebek katili savunan diyor...       1\n",
              "4     @meraldanis Dağdaki ler aç mı ?kaldı kurşunu b...       1\n",
              "...                                                 ...     ...\n",
              "1076                                              agree    <NA>\n",
              "1077                                           disagree    <NA>\n",
              "1078                                          agree/dis    <NA>\n",
              "1079                                              total    <NA>\n",
              "1080                                           subtotal    <NA>\n",
              "\n",
              "[1081 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b31dfd83-b77c-4740-a346-b3826d7cc44b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@meraldanis @Alone_36_ Sen o kadar vatansevers...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@meraldanis Erzurum'da kaza geçirmiş. Ne yazık...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@gulderenvarli Emekçi kürt halkın verdiği verg...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@meraldanis Bunlari bebek katili savunan diyor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@meraldanis Dağdaki ler aç mı ?kaldı kurşunu b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1076</th>\n",
              "      <td>agree</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1077</th>\n",
              "      <td>disagree</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1078</th>\n",
              "      <td>agree/dis</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1079</th>\n",
              "      <td>total</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1080</th>\n",
              "      <td>subtotal</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1081 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b31dfd83-b77c-4740-a346-b3826d7cc44b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b31dfd83-b77c-4740-a346-b3826d7cc44b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b31dfd83-b77c-4740-a346-b3826d7cc44b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0f726817-b22b-45f2-b862-fe08e2b51f12\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f726817-b22b-45f2-b862-fe08e2b51f12')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0f726817-b22b-45f2-b862-fe08e2b51f12 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_eb7b648c-7c58-4a5b-a9bf-fa69b2168d84\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('offensive_final')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eb7b648c-7c58-4a5b-a9bf-fa69b2168d84 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('offensive_final');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "offensive_final",
              "summary": "{\n  \"name\": \"offensive_final\",\n  \"rows\": 1081,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1080,\n        \"samples\": [\n          \"@hdpdemirtas @metinkilic59 \\u0130\\u015finiz g\\u00fcc\\u00fcn\\u00fcz ayr\\u0131\\u015ft\\u0131rma b\\u00f6l\\u00fcc\\u00fcl\\u00fck..\\u00c7erkes ilk defa m\\u0131 Mecliste olacak?\\n\\nDerdinizin fark\\u0131nday\\u0131z da..Allah vermese de bir \\u015fekilde belan\\u0131z\\u0131 bulacaks\\u0131n\\u0131z bunu bilin.\",\n          \"@Daccalaaa_34 @hsncml O senin anan\\u0131n taraf\\u0131ndan kar\\u0131\\u015ft\\u0131r\\u0131yorsun p*zeveng..\",\n          \"@meraldanis Lan senin \\u00e7ocuklar\\u0131n nerde okuyor arkada\\u015flar\\u0131n\\u0131n \\u00e7ocuklar\\u0131 nerdeler yurt d\\u0131\\u015f\\u0131nda milletin gariban\\u0131n \\u00e7ocuklar\\u0131n\\u0131 da\\u011fa g\\u00f6nderin kanlarindan siyaset yap\\u0131n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'offensive_final' is already loaded\n",
        "# Replace string '' with actual pd.NA\n",
        "offensive_final['labels'] = offensive_final['labels'].replace('', pd.NA)\n",
        "\n",
        "# Convert labels to nullable integer type\n",
        "offensive_final['labels'] = offensive_final['labels'].astype('Int64')\n",
        "\n",
        "# Drop rows where 'labels' is pd.NA\n",
        "offensive_final = offensive_final.dropna(subset=['labels'])\n",
        "\n",
        "# Verify the cleanup\n",
        "print(offensive_final['labels'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "863ANrPh_Rvu",
        "outputId": "e55b5cc1-faaa-4c98-ab35-581208ff36b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels\n",
            "1    612\n",
            "0    463\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final[\"labels\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-0zno7IES07",
        "outputId": "0d5e73e4-044b-442c-8fe2-ef1668c49f67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "labels\n",
              "1    612\n",
              "0    463\n",
              "Name: count, dtype: Int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U520ZBZTJG13",
        "outputId": "0672da4a-710e-46b6-cf17-0c1b94471bc2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      object\n",
              "labels     Int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final['labels'] = offensive_final['labels'].astype(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3TaAUz3IQMN",
        "outputId": "c161fc0f-c2dc-4c63-b5a5-e7489afb3216"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-9220c4dc9513>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  offensive_final['labels'] = offensive_final['labels'].astype(str)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE-DlmCyJMJG",
        "outputId": "3623a1d4-db6c-4486-df56-b196293eff7a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      object\n",
              "labels    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final[\"labels\"].value_counts()"
      ],
      "metadata": {
        "id": "9Tt8aGnCJho1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XUCiFUFOiXh",
        "outputId": "933a6ecd-678e-4026-9ee1-252b0a131f27"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      object\n",
              "labels    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final = offensive_final.reset_index(drop=True)\n",
        "hate = hate.reset_index(drop=True)\n",
        "\n",
        "# Concatenate the DataFrames along the columns\n",
        "offensive_final_concat = pd.concat([offensive_final, hate], axis=0)\n",
        "\n",
        "# Verify the result\n",
        "print(offensive_final_concat.head())"
      ],
      "metadata": {
        "id": "_TFmatyEOgJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final = offensive_final_concat"
      ],
      "metadata": {
        "id": "A74XdXaMPBU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final[\"labels\"].value_counts()"
      ],
      "metadata": {
        "id": "EVmLc-7vPJAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "OQYzPs33CUq4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(offensive_final, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "83txUnamCQFq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRAhp8ppGGP-",
        "outputId": "05a574ff-ffa3-4ad9-a0f9-a184d3b25494"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      object\n",
              "labels    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install peft urlextract ftfy"
      ],
      "metadata": {
        "id": "WByTrwySX-_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/pittsburgh-annotation/hate-speech-fırat-annotated.xlsx\")"
      ],
      "metadata": {
        "id": "Y15CEJhkdWwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Hate Speech\"] = df[\"Hate Speech\"].fillna(\"0\")\n",
        "df['Hate Speech'] = df['Hate Speech'].astype(int)"
      ],
      "metadata": {
        "id": "9bKfZlSXdkOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Hate Speech'].value_counts()"
      ],
      "metadata": {
        "id": "tMaK5oVafIch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={\"Hate Speech\":\"label\"},inplace=True)\n",
        "df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "6fHm1UCLfJt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "TGYDx9UBChx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"text\",\"label\"]]"
      ],
      "metadata": {
        "id": "d-IirvOpNSJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hate = df[df[\"label\"]==1]"
      ],
      "metadata": {
        "id": "PH1c53rKNWGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hate.rename(columns={\"label\":\"labels\"},inplace=True)"
      ],
      "metadata": {
        "id": "1Mn7M0pvNhX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hate[\"labels\"] = hate[\"labels\"].astype(str)"
      ],
      "metadata": {
        "id": "LbW5fkjuNnHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hate"
      ],
      "metadata": {
        "id": "9Zvevh3fNuf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final[\"labels\"].value_counts()"
      ],
      "metadata": {
        "id": "lv3jWmTAN6OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final[\"labels\"] = offensive_final[\"labels\"].astype(str)"
      ],
      "metadata": {
        "id": "iGl39UjqOB5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final = pd.merge(offensive_final , hate , on=\"labels\")"
      ],
      "metadata": {
        "id": "0MQwuNt0NxDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final[\"labels\"].value_counts()"
      ],
      "metadata": {
        "id": "aDCIMYMpOJDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_json(\"/content/drive/MyDrive/pittsburgh-annotation/hate_binary_train.json\",orient=\"records\",lines=True)"
      ],
      "metadata": {
        "id": "k2mwyyCtCWnq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_final.to_json(\"/content/drive/MyDrive/pittsburgh-annotation/hate_binary.json\",orient=\"records\",lines=True)"
      ],
      "metadata": {
        "id": "L8BX3EKOEYBc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_json(\"/content/drive/MyDrive/pittsburgh-annotation/hate_binary_test.json\",orient=\"records\",lines=True)"
      ],
      "metadata": {
        "id": "X--IoA85CgV2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, matthews_corrcoef\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import os\n",
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "\n",
        "class TransformersData(torch.utils.data.Dataset):\n",
        "    def __init__(self, examples, label_map, tokenizer, binary=False, max_seq_length=512, has_token_type_ids=False, with_label=True):\n",
        "        self.examples = examples\n",
        "        self.label_map = label_map\n",
        "        self.binary = binary\n",
        "\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.with_label = with_label\n",
        "        self.has_token_type_ids = has_token_type_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.examples[idx]\n",
        "        encoded_input = self.tokenizer(ex[0], padding=\"max_length\", truncation=True, max_length=self.max_seq_length)\n",
        "        input_ids = torch.tensor(encoded_input[\"input_ids\"], dtype=torch.long)\n",
        "        input_mask = torch.tensor(encoded_input[\"attention_mask\"], dtype=torch.long)\n",
        "        if self.has_token_type_ids:\n",
        "            token_type_ids = torch.tensor(encoded_input[\"token_type_ids\"], dtype=torch.long)\n",
        "\n",
        "        if self.with_label:\n",
        "            if self.binary:\n",
        "                label_ids = torch.FloatTensor([self.label_map[int(ex[1])]])\n",
        "            else:\n",
        "                label_ids = torch.tensor(self.label_map[int(ex[1])], dtype=torch.long)\n",
        "\n",
        "            if self.has_token_type_ids:\n",
        "                return input_ids, input_mask, token_type_ids, label_ids\n",
        "            else:\n",
        "                return input_ids, input_mask, label_ids\n",
        "\n",
        "        if self.has_token_type_ids:\n",
        "            return input_ids, input_mask, token_type_ids\n",
        "        else:\n",
        "            return input_ids, input_mask\n",
        "\n",
        "def get_examples(filename, with_label=True):\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.read().splitlines()\n",
        "\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "        line = json.loads(line)\n",
        "        text = str(line[\"text\"])\n",
        "        if with_label:\n",
        "            label = int(line[\"labels\"])\n",
        "            examples.append([text, label])\n",
        "        else:\n",
        "            examples.append([text])\n",
        "\n",
        "    return examples\n",
        "\n",
        "# INPUTS\n",
        "pretrained_transformers_model = \"dbmdz/bert-base-turkish-128k-cased\" # Pretrained model\n",
        "seed = 42\n",
        "max_seq_length = 512 # max length of a document (in tokens)\n",
        "batch_size = 8\n",
        "dev_ratio = 0.1\n",
        "\n",
        "# MUST SET THESE VALUES\n",
        "repo_path = \"/content/drive/MyDrive/pittsburgh-annotation\"\n",
        "train_filename = repo_path + \"/hate_binary_train.json\"\n",
        "test_filename = repo_path + \"/hate_binary_test.json\"\n",
        "only_test = False # Only perform testing\n",
        "predict = False # Predict instead of testing\n",
        "has_token_type_ids = False\n",
        "\n",
        "# Define label lists and mappings for binary classification\n",
        "label_list = [0, 1]  # Directly using integers as labels\n",
        "label_to_idx = {label: idx for idx, label in enumerate(label_list)}\n",
        "idx_to_label = {idx: label for idx, label in enumerate(label_list)}\n",
        "\n",
        "# Load the dataset and perform resampling\n",
        "offensive_final = pd.read_json(\"/content/drive/MyDrive/pittsburgh-annotation/hate_binary.json\", orient=\"records\", lines=True)\n",
        "df_majority = offensive_final[offensive_final.labels == 0]\n",
        "df_minority = offensive_final[offensive_final.labels == 1]\n",
        "\n",
        "df_minority_upsampled = resample(df_minority,\n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=len(df_majority),    # to match majority class\n",
        "                                 random_state=123) # reproducible results\n",
        "\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "# Save the upsampled data to train_filename\n",
        "df_upsampled.to_json(train_filename, orient='records', lines=True)\n",
        "\n",
        "# SETTINGS\n",
        "binary = len(label_list) == 2\n",
        "learning_rate = 2e-5\n",
        "dev_metric = \"f1_macro\"\n",
        "num_epochs = 10\n",
        "dev_set_splitting = \"random\" # random, or any filename\n",
        "use_gpu = True\n",
        "device_ids = [0] # if not multi-gpu then pass a single number such as [0]\n",
        "positive_threshold = 0.5 # Outputted probabilities bigger than this number is considered positive in case of binary classifications\n",
        "return_probabilities = False # whether or not to return probabilities instead of labels when predicting\n",
        "model_path = \"{}_{}_{}_{:.2f}_{}.pt\".format(pretrained_transformers_model.replace(\"/\", \"_\"), max_seq_length, batch_size, dev_ratio, seed)\n",
        "\n",
        "# optional, used in testing\n",
        "classifier_path = \"\"\n",
        "encoder_path = \"\"\n",
        "\n",
        "if not classifier_path:\n",
        "    classifier_path =  repo_path + \"/models/classifier_hate_binary_\" + model_path\n",
        "if not encoder_path:\n",
        "    encoder_path =  repo_path + \"/models/encoder_hate_binary_\" + model_path\n",
        "\n",
        "if return_probabilities:\n",
        "    from scipy.special import softmax\n",
        "\n",
        "if use_gpu and torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:%d\"%(device_ids[0]))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "tokenizer = None\n",
        "criterion = torch.nn.BCEWithLogitsLoss() if binary else torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "def test_model(encoder, classifier, dataloader):\n",
        "    all_preds = []\n",
        "    all_label_ids = []\n",
        "    eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    for val_step, batch in enumerate(dataloader):\n",
        "        if has_token_type_ids:\n",
        "            input_ids, input_mask, token_type_ids, label_ids = tuple(t.to(device) for t in batch)\n",
        "            embeddings = encoder(input_ids, attention_mask=input_mask, token_type_ids=token_type_ids)[1]\n",
        "        else:\n",
        "            input_ids, input_mask, label_ids = tuple(t.to(device) for t in batch)\n",
        "            embeddings = encoder(input_ids, attention_mask=input_mask)[1]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = classifier(embeddings)\n",
        "            tmp_eval_loss = criterion(out, label_ids)\n",
        "\n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "\n",
        "        if binary:\n",
        "            curr_preds = torch.sigmoid(out).detach().cpu().numpy().flatten()\n",
        "            curr_preds = [int(x >= positive_threshold) for x in curr_preds]\n",
        "            all_preds += curr_preds\n",
        "        else:\n",
        "            out = out.detach().cpu().numpy()\n",
        "            all_preds += np.argmax(out, axis=1).tolist()\n",
        "\n",
        "        label_ids = label_ids.to('cpu').numpy().flatten().tolist()\n",
        "        all_label_ids += label_ids\n",
        "\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_label_ids, all_preds, average=\"macro\", labels=list(range(0,len(label_list))))\n",
        "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(all_label_ids, all_preds, average=\"micro\", labels=list(range(0,len(label_list))))\n",
        "    mcc = matthews_corrcoef(all_preds, all_label_ids)\n",
        "    eval_loss /= nb_eval_steps\n",
        "    result = {\"precision_macro\": precision,\n",
        "              \"recall_macro\": recall,\n",
        "              \"f1_macro\": f1,\n",
        "              \"precision_micro\": precision_micro,\n",
        "              \"recall_micro\": recall_micro,\n",
        "              \"f1_micro\": f1_micro,\n",
        "              \"mcc\": mcc}\n",
        "\n",
        "    return result, eval_loss\n",
        "\n",
        "\n",
        "def model_predict(encoder, classifier, dataloader):\n",
        "    all_preds = []\n",
        "    for val_step, batch in enumerate(dataloader):\n",
        "        if has_token_type_ids:\n",
        "            input_ids, input_mask, token_type_ids = tuple(t.to(device) for t in batch)\n",
        "            embeddings = encoder(input_ids, attention_mask=input_mask, token_type_ids=token_type_ids)[1]\n",
        "        else:\n",
        "            input_ids, input_mask = tuple(t.to(device) for t in batch)\n",
        "            embeddings = encoder(input_ids, attention_mask=input_mask)[1]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = classifier(embeddings)\n",
        "\n",
        "        if binary:\n",
        "            curr_preds = torch.sigmoid(out).detach().cpu().numpy().flatten()\n",
        "            if return_probabilities:\n",
        "                curr_preds = [round(float(x), 4) for x in curr_preds]\n",
        "            else:\n",
        "                curr_preds = [idx_to_label[int(x >= positive_threshold)] for x in curr_preds]\n",
        "            all_preds += curr_preds\n",
        "\n",
        "        else:\n",
        "            out = out.detach().cpu().numpy()\n",
        "            if return_probabilities:\n",
        "                curr_preds = [probs for probs in softmax(out, axis=1).tolist()] # a list of lists(of probabilities)\n",
        "            else:\n",
        "                curr_preds = [idx_to_label[pred] for pred in np.argmax(out, axis=1).tolist()] # a list of labels\n",
        "            all_preds += curr_preds\n",
        "\n",
        "    return all_preds\n",
        "\n",
        "\n",
        "def build_model(train_examples, dev_examples, pretrained_model, n_epochs=10, curr_model_path=\"temp.pt\"):\n",
        "    global tokenizer\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
        "    encoder = AutoModel.from_pretrained(pretrained_model)\n",
        "    classifier = torch.nn.Linear(encoder.config.hidden_size, 1 if binary else len(label_list))\n",
        "\n",
        "    train_dataset = TransformersData(train_examples, label_to_idx, tokenizer, binary=binary, max_seq_length=max_seq_length, has_token_type_ids=has_token_type_ids)\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    dev_dataset = TransformersData(dev_examples, label_to_idx, tokenizer, binary=binary, max_seq_length=max_seq_length, has_token_type_ids=has_token_type_ids)\n",
        "    dev_dataloader = DataLoader(dataset=dev_dataset, batch_size=batch_size)\n",
        "\n",
        "    classifier.to(device)\n",
        "    if torch.cuda.device_count() > 1 and device.type == \"cuda\" and len(device_ids) > 1:\n",
        "        encoder = torch.nn.DataParallel(encoder, device_ids=device_ids)\n",
        "    encoder.to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(list(classifier.parameters()) + list(encoder.parameters()), lr=learning_rate)\n",
        "    num_train_steps = int(len(train_examples) / batch_size * num_epochs)\n",
        "    # scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "    #                                             num_warmup_steps = 0,\n",
        "    #                                             num_training_steps = num_train_steps)\n",
        "\n",
        "    best_score = -1e6\n",
        "    for epoch in range(n_epochs):\n",
        "        start_time = time.time()\n",
        "        train_loss = 0\n",
        "        encoder.train()\n",
        "        classifier.train()\n",
        "\n",
        "        print(\"Starting Epoch %d\"%(epoch+1))\n",
        "        global_step = 0\n",
        "        train_loss = 0.0\n",
        "        nb_tr_steps = 0\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "            if has_token_type_ids:\n",
        "                input_ids, input_mask, token_type_ids, label_ids = tuple(t.to(device) for t in batch)\n",
        "                embeddings = encoder(input_ids, attention_mask=input_mask, token_type_ids=token_type_ids)[1]\n",
        "            else:\n",
        "                input_ids, input_mask, label_ids = tuple(t.to(device) for t in batch)\n",
        "                embeddings = encoder(input_ids, attention_mask=input_mask)[1]\n",
        "\n",
        "            out = classifier(embeddings)\n",
        "            loss = criterion(out, label_ids)\n",
        "\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), 1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(classifier.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            # scheduler.step()\n",
        "            encoder.zero_grad()\n",
        "            classifier.zero_grad()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= nb_tr_steps\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        # Validation\n",
        "        encoder.eval()\n",
        "        classifier.eval()\n",
        "        result, val_loss = test_model(encoder, classifier, dev_dataloader)\n",
        "        result[\"train_loss\"] = train_loss\n",
        "        result[\"dev_loss\"] = val_loss\n",
        "        result[\"elapsed\"] = elapsed\n",
        "        print(\"***** Epoch \" + str(epoch + 1) + \" *****\")\n",
        "        for key in sorted(result.keys()):\n",
        "            print(\"  %s = %.6f\" %(key, result[key]))\n",
        "\n",
        "        print(\"Val score: %.6f\" %result[dev_metric])\n",
        "\n",
        "        if result[dev_metric] > best_score:\n",
        "            print(\"Saving model!\")\n",
        "            if not os.path.exists(repo_path + \"/models\"):\n",
        "                os.makedirs(repo_path + \"/models\")\n",
        "            torch.save(classifier.state_dict(), repo_path + \"/models/classifier_\" + curr_model_path)\n",
        "            encoder_to_save = encoder.module if hasattr(encoder, 'module') else encoder  # To handle multi gpu\n",
        "            torch.save(encoder_to_save.state_dict(), repo_path + \"/models/encoder_\" + curr_model_path)\n",
        "            best_score = result[dev_metric]\n",
        "\n",
        "        print(\"------------------------------------------------------------------------\")\n",
        "\n",
        "    return encoder, classifier\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if dev_set_splitting == \"random\":\n",
        "        train_examples = get_examples(train_filename)\n",
        "        random.shuffle(train_examples)\n",
        "        dev_split = int(len(train_examples) * dev_ratio)\n",
        "        dev_examples = train_examples[:dev_split]\n",
        "        train_examples = train_examples[dev_split:]\n",
        "    else: # it's a custom filename\n",
        "        train_examples = get_examples(train_filename)\n",
        "        random.shuffle(train_examples)\n",
        "        dev_examples = get_examples(dev_set_splitting)\n",
        "\n",
        "    if not only_test:\n",
        "        encoder, classifier = build_model(train_examples, dev_examples, pretrained_transformers_model, n_epochs=num_epochs, curr_model_path=model_path)\n",
        "        classifier.load_state_dict(torch.load(repo_path + \"/models/classifier_\" + model_path))\n",
        "        if torch.cuda.device_count() > 1 and device.type == \"cuda\" and len(device_ids) > 1:\n",
        "            encoder.module.load_state_dict(torch.load(repo_path + \"/models/encoder_\" + model_path))\n",
        "        else:\n",
        "            encoder.load_state_dict(torch.load(repo_path + \"/models/encoder_\" + model_path))\n",
        "    else:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(pretrained_transformers_model)\n",
        "        encoder = AutoModel.from_pretrained(pretrained_transformers_model)\n",
        "        classifier = torch.nn.Linear(encoder.config.hidden_size, 1 if binary else len(label_list))\n",
        "\n",
        "        classifier.to(device)\n",
        "        encoder.to(device)\n",
        "        classifier.load_state_dict(torch.load(classifier_path, map_location=device))\n",
        "        encoder.load_state_dict(torch.load(encoder_path, map_location=device))\n",
        "\n",
        "        if torch.cuda.device_count() > 1 and device.type == \"cuda\" and len(device_ids) > 1:\n",
        "            encoder = torch.nn.DataParallel(encoder, device_ids=device_ids)\n",
        "\n",
        "    encoder.eval()\n",
        "    classifier.eval()\n",
        "\n",
        "    if predict:\n",
        "        test_examples = get_examples(test_filename, with_label=False)\n",
        "        test_dataset = TransformersData(test_examples, label_to_idx, tokenizer, binary=binary, max_seq_length=max_seq_length, has_token_type_ids=has_token_type_ids, with_label=False)\n",
        "        test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
        "\n",
        "        all_preds = model_predict(encoder, classifier, test_dataloader)\n",
        "        with open(test_filename, \"r\", encoding=\"utf-8\") as f:\n",
        "            test = [json.loads(line) for line in f.read().splitlines()]\n",
        "\n",
        "        with open(repo_path + \"/out.json\", \"w\", encoding=\"utf-8\") as g:\n",
        "            for i, t in enumerate(test):\n",
        "                t[\"prediction\"] = all_preds[i]\n",
        "                g.write(json.dumps(t) + \"\\n\")\n",
        "\n",
        "    else:\n",
        "        test_examples = get_examples(test_filename)\n",
        "        test_dataset = TransformersData(test_examples, label_to_idx, tokenizer, binary=binary, max_seq_length=max_seq_length, has_token_type_ids=has_token_type_ids)\n",
        "        test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
        "\n",
        "        result, test_loss = test_model(encoder, classifier, test_dataloader)\n",
        "        result[\"test_loss\"] = test_loss\n",
        "\n",
        "        print(\"***** TEST RESULTS *****\")\n",
        "        for key in sorted(result.keys()):\n",
        "            print(\"  %s = %.6f\" %(key, result[key]))\n",
        "\n",
        "        print(\"TEST SCORE: %.6f\" %result[dev_metric])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9JsScrd_Rrk",
        "outputId": "2044a290-8cb4-4585-d058-bf1106a7d3e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 1 *****\n",
            "  dev_loss = 0.577945\n",
            "  elapsed = 37.651829\n",
            "  f1_macro = 0.696147\n",
            "  f1_micro = 0.706522\n",
            "  mcc = 0.422328\n",
            "  precision_macro = 0.723162\n",
            "  precision_micro = 0.706522\n",
            "  recall_macro = 0.699811\n",
            "  recall_micro = 0.706522\n",
            "  train_loss = 0.655365\n",
            "Val score: 0.696147\n",
            "Saving model!\n",
            "------------------------------------------------------------------------\n",
            "Starting Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 2 *****\n",
            "  dev_loss = 0.589796\n",
            "  elapsed = 37.414921\n",
            "  f1_macro = 0.767089\n",
            "  f1_micro = 0.771739\n",
            "  mcc = 0.549529\n",
            "  precision_macro = 0.782707\n",
            "  precision_micro = 0.771739\n",
            "  recall_macro = 0.767045\n",
            "  recall_micro = 0.771739\n",
            "  train_loss = 0.494226\n",
            "Val score: 0.767089\n",
            "Saving model!\n",
            "------------------------------------------------------------------------\n",
            "Starting Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 3 *****\n",
            "  dev_loss = 0.871271\n",
            "  elapsed = 37.019084\n",
            "  f1_macro = 0.751351\n",
            "  f1_micro = 0.760870\n",
            "  mcc = 0.540868\n",
            "  precision_macro = 0.788172\n",
            "  precision_micro = 0.760870\n",
            "  recall_macro = 0.753788\n",
            "  recall_micro = 0.760870\n",
            "  train_loss = 0.249943\n",
            "Val score: 0.751351\n",
            "------------------------------------------------------------------------\n",
            "Starting Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 4 *****\n",
            "  dev_loss = 1.600783\n",
            "  elapsed = 37.382723\n",
            "  f1_macro = 0.720081\n",
            "  f1_micro = 0.739130\n",
            "  mcc = 0.521397\n",
            "  precision_macro = 0.796569\n",
            "  precision_micro = 0.739130\n",
            "  recall_macro = 0.729167\n",
            "  recall_micro = 0.739130\n",
            "  train_loss = 0.084468\n",
            "Val score: 0.720081\n",
            "------------------------------------------------------------------------\n",
            "Starting Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 5 *****\n",
            "  dev_loss = 1.938563\n",
            "  elapsed = 37.271057\n",
            "  f1_macro = 0.710145\n",
            "  f1_micro = 0.728261\n",
            "  mcc = 0.491267\n",
            "  precision_macro = 0.775821\n",
            "  precision_micro = 0.728261\n",
            "  recall_macro = 0.718750\n",
            "  recall_micro = 0.728261\n",
            "  train_loss = 0.043072\n",
            "Val score: 0.710145\n",
            "------------------------------------------------------------------------\n",
            "Starting Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 6 *****\n",
            "  dev_loss = 1.465606\n",
            "  elapsed = 37.228642\n",
            "  f1_macro = 0.799710\n",
            "  f1_micro = 0.804348\n",
            "  mcc = 0.619365\n",
            "  precision_macro = 0.820487\n",
            "  precision_micro = 0.804348\n",
            "  recall_macro = 0.799242\n",
            "  recall_micro = 0.804348\n",
            "  train_loss = 0.021833\n",
            "Val score: 0.799710\n",
            "Saving model!\n",
            "------------------------------------------------------------------------\n",
            "Starting Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 7 *****\n",
            "  dev_loss = 1.727190\n",
            "  elapsed = 37.347004\n",
            "  f1_macro = 0.751351\n",
            "  f1_micro = 0.760870\n",
            "  mcc = 0.540868\n",
            "  precision_macro = 0.788172\n",
            "  precision_micro = 0.760870\n",
            "  recall_macro = 0.753788\n",
            "  recall_micro = 0.760870\n",
            "  train_loss = 0.024825\n",
            "Val score: 0.751351\n",
            "------------------------------------------------------------------------\n",
            "Starting Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 8 *****\n",
            "  dev_loss = 1.917705\n",
            "  elapsed = 37.357524\n",
            "  f1_macro = 0.751351\n",
            "  f1_micro = 0.760870\n",
            "  mcc = 0.540868\n",
            "  precision_macro = 0.788172\n",
            "  precision_micro = 0.760870\n",
            "  recall_macro = 0.753788\n",
            "  recall_micro = 0.760870\n",
            "  train_loss = 0.011936\n",
            "Val score: 0.751351\n",
            "------------------------------------------------------------------------\n",
            "Starting Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 9 *****\n",
            "  dev_loss = 1.493962\n",
            "  elapsed = 37.329214\n",
            "  f1_macro = 0.790483\n",
            "  f1_micro = 0.793478\n",
            "  mcc = 0.590408\n",
            "  precision_macro = 0.800737\n",
            "  precision_micro = 0.793478\n",
            "  recall_macro = 0.789773\n",
            "  recall_micro = 0.793478\n",
            "  train_loss = 0.016913\n",
            "Val score: 0.790483\n",
            "------------------------------------------------------------------------\n",
            "Starting Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 104/104 [00:37<00:00,  2.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Epoch 10 *****\n",
            "  dev_loss = 2.232972\n",
            "  elapsed = 37.301705\n",
            "  f1_macro = 0.726190\n",
            "  f1_micro = 0.739130\n",
            "  mcc = 0.501688\n",
            "  precision_macro = 0.772321\n",
            "  precision_micro = 0.739130\n",
            "  recall_macro = 0.731061\n",
            "  recall_micro = 0.739130\n",
            "  train_loss = 0.011982\n",
            "Val score: 0.726190\n",
            "------------------------------------------------------------------------\n",
            "***** TEST RESULTS *****\n",
            "  f1_macro = 0.920869\n",
            "  f1_micro = 0.920930\n",
            "  mcc = 0.848506\n",
            "  precision_macro = 0.922817\n",
            "  precision_micro = 0.920930\n",
            "  recall_macro = 0.925693\n",
            "  recall_micro = 0.920930\n",
            "  test_loss = 0.550930\n",
            "TEST SCORE: 0.920869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0fyD_COg_RpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28m4m5On_Rm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQTr6BMo_Rke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfgyFeFN_Rf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "006UaJWt_Rdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vreQn7j5_RaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8RELVE5_RX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "irHW2Q4Y_RWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FqjuaEr4_RUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UWUj8NPU_RRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHoThhwz_RPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NcTkvoHv_RMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKoFekSg_RIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fwkfPyNk_RGt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}